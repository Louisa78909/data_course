{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Loading-Image-Data\" data-toc-modified-id=\"Loading-Image-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading Image Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Initial-Examination\" data-toc-modified-id=\"Initial-Examination-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Initial Examination</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exercise:-Make-a-plot-of-a-slice-of-the-brain-(bonus:-and-the-corresponding-segmentation).\" data-toc-modified-id=\"Exercise:-Make-a-plot-of-a-slice-of-the-brain-(bonus:-and-the-corresponding-segmentation).-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span><em>Exercise</em>: Make a plot of a slice of the brain (bonus: and the corresponding segmentation).</a></span></li></ul></li></ul></li><li><span><a href=\"#xArray-Dataset\" data-toc-modified-id=\"xArray-Dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>xArray Dataset</a></span></li><li><span><a href=\"#Advanced-Visualization\" data-toc-modified-id=\"Advanced-Visualization-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Advanced Visualization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Simple-Slice-Viewing-with-Holoviews\" data-toc-modified-id=\"Simple-Slice-Viewing-with-Holoviews-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Simple Slice Viewing with Holoviews</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exercise:-Why-do-we-have-to-flip-the-y-axis?-How-can-we-do-this-within-the-data,-before-plotting?\" data-toc-modified-id=\"Exercise:-Why-do-we-have-to-flip-the-y-axis?-How-can-we-do-this-within-the-data,-before-plotting?-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span><em>Exercise</em>: Why do we have to flip the y axis? How can we do this within the data, before plotting?</a></span></li></ul></li><li><span><a href=\"#Multi-slice-Viewing\" data-toc-modified-id=\"Multi-slice-Viewing-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Multi-slice Viewing</a></span></li><li><span><a href=\"#Alpha-Blending\" data-toc-modified-id=\"Alpha-Blending-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Alpha Blending</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Imaging Analysis and xArray\n",
    "Computer vision projects are commonplace in data science.  Typically, we have a large set of input images that need some sort of preprocessing and manipulation before we can crank them through some sort of ML architecture.  Ideally, we would like to have all images in a data structure in which we can quickly and easily analyze their content, perform operations, group and index, assign metadata and additional features, and so on.  Also, it would be nice if we could use a similar structure and API to `pandas` in order to minimize aggravation on our end.\n",
    "\n",
    "[xArray](http://xarray.pydata.org/en/stable/) is a data structure built with multi-dimensional data in mind.  It is modeled very closely after `pandas`, and can be used to store a large set of images and additional data.\n",
    "\n",
    "The dataset we'll be examining is a series of abdominal MRI sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Image Data\n",
    "Medical image data is typically stored as one of a number of image formats (DICOM, Nifti, MGH, etc), in order to maintain necessary metadata that corresponds to (among other things) the physical origin and spacing between the pixels of an image.  This information is not including in a simple array, which is needed when eventually invoking a tool like `pytorch`.  Because of this, we'll need to use a DICOM/Nifti image reader, so we'll be using `SimpleITK` to help with some image manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoload if needed\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting setup\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.rcParams['figure.figsize'] = (10,8)\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh', 'matplotlib')\n",
    "\n",
    "# Basic imports\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import SimpleITK as sitk\n",
    "import nibabel as nib\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Examination\n",
    "We're going to look at brain images for this module.  Specifically, they are 3D volumes with associated segmentation maps.  We'd like to view them and manipulate them in a manner that's fast and easy, and integrates easily into our workflow and data processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls /pghbio/dbmi/batmanlab/bpollack/data_course/data_sets/brains/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /pghbio/dbmi/batmanlab/bpollack/data_course/data_sets/brains/140820_YF58DB_FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the full path to the data\n",
    "data_dir = '/pghbio/dbmi/batmanlab/bpollack/data_course/data_sets/brains'\n",
    "patient = '140820_YF58DB_FS'\n",
    "# load in a sample image using nibabel\n",
    "brain_mri = nib.load(str(Path(data_dir, patient, 'norm.mgz')))\n",
    "brain_seg = nib.load(str(Path(data_dir, patient, 'aseg.mgz')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(brain_mri.header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the above information tell us? Importantly, we have an image of 256x256x256 pixels with 1 value per pixel.  The physical spacing is 1mm per pixel.  There is a rotation matrix defining the transformation from image space to physical space.  For more info, follow this link: https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/MghFormat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*: Make a plot of a slice of the brain (bonus: and the corresponding segmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some plots\n",
    "brain_mri_img = brain_mri.get_fdata()\n",
    "brain_seg_img = brain_seg.get_fdata()\n",
    "# Plot the brain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pieces are ready to go, but as it currently stands, they are not in format in which we can easily perform large-scale investigation over the entire dataset.  It would be very convenient if we could load all patients into an object that allowed quick, easy, transparent access to the data. Let's take a look at xArray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xArray Dataset\n",
    "xArray is the multidimensional analogue to pandas.  This makes it a very attractive tool when dealing with medical imaging (especially when all the images are very uniform in shape). A Dataset has `dims`, `data_vars`, and `coords` (and user-defined `attrs` for metadata).  Let's make a simple dataset then examine it's properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an xarray object and assign names\n",
    "ds = xr.Dataset({'MRI': (['subject', 'w', 'h', 'd'],\n",
    "                            np.zeros((4, 256, 256, 256), dtype=np.float32)),\n",
    "                 'seg': (['subject', 'w', 'h', 'd'],\n",
    "                            np.zeros((4, 256, 256, 256), dtype=np.float32)),\n",
    "                },\n",
    "                coords={'subject': ['140820_YF58DB_FS', '110306_QW55XU_FS', '131205_SX49HC_FS', '090706_JW54JH_FS'],\n",
    "                       'w':range(256),\n",
    "                       'h':range(256),\n",
    "                       'd':range(256),\n",
    "                       }\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the xarray object with the patient images\n",
    "for subj in ['140820_YF58DB_FS', '110306_QW55XU_FS', '131205_SX49HC_FS', '090706_JW54JH_FS']:\n",
    "    # Much like pandas, when assigning new values to a variable, it's safest to use 'loc'\n",
    "    # to guarantee that we are assiging to the actual dataset and not a copy\n",
    "    tmp_mri = nib.load(str(Path(data_dir, subj, 'norm.mgz'))).get_fdata()\n",
    "    tmp_seg = nib.load(str(Path(data_dir, subj, 'aseg.mgz'))).get_fdata()\n",
    "    ds['MRI'].loc[{'subject':subj}] = tmp_mri\n",
    "    ds['seg'].loc[{'subject':subj}] = tmp_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(subject='140820_YF58DB_FS', d=100)['MRI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's plot via the xarray\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15,8))\n",
    "axes = np.ravel(axes)\n",
    "axes[0].imshow(ds.sel(subject='131205_SX49HC_FS', w=100).MRI)\n",
    "axes[1].imshow(ds.sel(subject='131205_SX49HC_FS', w=100).seg, cmap=seg_cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Visualization\n",
    "Let's go beyond matplotlib.  In this section, we will explore the usage of holoviews for interactive visualization.  Holoviews works natively with xArray objects, which will be to our benefit.  We'll start simple and scale up to a simple function that handles a lot of our visualization needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Slice Viewing with Holoviews\n",
    "Before we get too fancy, let's reproduce the type of plots we've already made in matplotlib, but using holoviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = hv.Image(ds.sel(w=100, subject='131205_SX49HC_FS'), vdims=['MRI'], kdims=['d', 'h'])\n",
    "# img.opts(invert_yaxis=True, width=500, height=500, cmap='viridis')\n",
    "img.opts(width=500, height=500, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*: Why do we have to flip the y axis? How can we do this within the data, before plotting?\n",
    "https://dsp.stackexchange.com/questions/35925/why-do-we-use-the-top-left-corner-as-the-origin-in-image-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the coordinates for x, y, z.  This gives us our standard views of the brain for axial, coronal, and sagittal.\n",
    "ds = ds.assign_coords(w=range(256)[::-1], h=range(256)[::-1], d=range(256)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hv.Image(ds.sel(w=128, subject='131205_SX49HC_FS'), vdims=['MRI'], kdims=['d', 'h'], label='Sagittal')\n",
    " + hv.Image(ds.sel(h=128, subject='131205_SX49HC_FS'), vdims=['MRI'], kdims=['w', 'd'], label='Axial')\n",
    " + hv.Image(ds.sel(d=128, subject='131205_SX49HC_FS'), vdims=['MRI'], kdims=['w', 'h'], label='Coronal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-slice Viewing\n",
    "So far, there's been no real benefit for using holoviews over standard matplotlib (in fact, holoviews is a little more cumbersome).  That's all about to change.  To maximize our benefit from holoviews, we'll make a holoviews dataset directly from our xarray object, and that will be used for our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making our holoviews dataset\n",
    "hv_ds = hv.Dataset(ds['MRI'])\n",
    "hv_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some default options for \"Image\"\n",
    "from holoviews import opts\n",
    "opts.defaults(opts.Image(cmap='viridis', width=400, height=400, tools=['hover']))\n",
    "              \n",
    "hv_brain_image = hv_ds.to(hv.Image, groupby=['subject', 'w'], dynamic=True, kdims=['d', 'h'])\n",
    "print(hv_brain_image)\n",
    "hv_brain_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the downsides of using 'dynamic=True' is that holoviews can't figure out an appropriate colormap range for the whole image so, each slice has it's own.\n",
    "# Let's try to do something about that.\n",
    "# Note, we can get the original xarray format by calling 'data' on our holoviews dataset\n",
    "print(hv_ds.data.MRI.min())\n",
    "print(hv_ds.data.MRI.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_brain_image.redim.range(MRI=(0, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making our holoviews datasets\n",
    "hv_ds_MRI = hv.Dataset(ds['MRI']) # MRI\n",
    "hv_ds_seg = hv.Dataset(ds['seg']) # Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two dynamic images, plot them side by side\n",
    "dyn_MRI = hv_ds_MRI.to(hv.Image, groupby=['subject', 'w'], dynamic=True, kdims=['d', 'h']).redim.range(MRI=(0,150))\n",
    "dyn_seg = hv_ds_seg.to(hv.Image, groupby=['subject', 'w'], dynamic=True, kdims=['d', 'h']).opts(cmap=seg_cmap).redim.range(seg=(0,255))\n",
    "# use '+' to plot both side by side\n",
    "dyn_MRI+dyn_seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a particular segmentation value and see if we can isolate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See our segmentation values\n",
    "np.unique(ds['seg'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new segmentation dataset\n",
    "# Select seg==2, make all the other values 0\n",
    "hv_ds_seg_single = hv.Dataset(ds.where(ds.seg==2).fillna(0)['seg']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_seg_single = hv_ds_seg_single.to(hv.Image, groupby=['subject', 'w'],\n",
    "                                     dynamic=True, kdims=['d', 'h']).opts(cmap=seg_cmap).redim.range(seg=(0,255))\n",
    "# use '+' to plot both side by side\n",
    "dyn_MRI+dyn_seg_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Blending\n",
    "Overlaying images on top of one another is a very useful technique for quick verification and comparison.  There are many ways to approach this, but I prefer alpha blending, in which an image with variable transparency is overlaid on another.  Let's try to accomplish that in the holoviews framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "# make a new hv dataset, but set all 0s to NaNs (NaNs are transparent)\n",
    "hv_ds_seg_overlay = hv.Dataset(ds.where(ds.seg>0)['seg']) \n",
    "dyn_seg_overlay = hv_ds_seg_overlay.to(hv.Image, groupby=['subject', 'w'],\n",
    "                                     dynamic=True, kdims=['d', 'h']).opts(cmap=cmap_seg).redim.range(seg=(0,255))\n",
    "\n",
    "# Make an alpha slider\n",
    "slider = pn.widgets.FloatSlider(start=0, end=1, value=0.0, name='mask')\n",
    "# Plot the slider and the overlayed images using the '*' operator\n",
    "pn.Column(slider, dyn_MRI.redim.range(MRI=(0,150))*dyn_seg_overlay.apply.opts(alpha=slider.param.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
